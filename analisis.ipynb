{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4dfbab0-b4f9-46f1-9923-27b315fff25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "import openpyxl\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\", font_scale=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "194e0906-506f-4605-b5ca-1c56294b6ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2123e851-9f1c-4480-acab-f0b05afe09fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "AÑOS_A_PROCESAR = [str(año) for año in range(2019, 2024)] # ['2019', '2020', '2021', '2022', '2023']\n",
    "\n",
    "RUTA_BASE_DATOS = 'data'\n",
    "SUBCARPETAS = ['difusas', 'puntuales', 'ruta'] \n",
    "CARPETA_GRAFICOS = f'graficos_{AÑOS_A_PROCESAR[0]}-{AÑOS_A_PROCESAR[-1]}_reporte_es'\n",
    "\n",
    "NOMBRE_CIUDAD_FILTRO = 'Valdivia'\n",
    "NOMBRE_MP25 = 'MP2.5'\n",
    "NOMBRE_MP10 = 'MP10'\n",
    "TOP_N_CONTAMINANTES_CIUDAD = 20\n",
    "\n",
    "MAPA_CONTAMINANTES = {\n",
    "    'NOx ': 'NOx', 'Nitrogen oxides (NOx)': 'NOx',\n",
    "    'Compuestos Orgánicos Volátiles': 'COV', 'Volatile organic compounds (VOC)': 'COV',\n",
    "    'Carbon dioxide': 'Dióxido de carbono (CO2)',\n",
    "    'Carbon monoxide': 'Monóxido de carbono (CO)', 'Monóxido de carbono': 'Monóxido de carbono (CO)',\n",
    "    'Sulfur dioxide': 'Dióxido de azufre (SO2)', 'Dióxido de azúfre (SO2)': 'Dióxido de azufre (SO2)',\n",
    "    'Sulfur oxides (SOx)': 'SOx',\n",
    "    'Arsenic': 'Arsénico',\n",
    "    'Lead': 'Plomo',\n",
    "    'Mercury': 'Mercurio',\n",
    "    'Ammonia': 'Amoniaco (NH3)', 'Nitrógeno amoniacal (o NH3)': 'Amoniaco (NH3)',\n",
    "    'MP2,5': NOMBRE_MP25, 'PM2.5, primary': NOMBRE_MP25, 'MP2.5': NOMBRE_MP25,\n",
    "    'PM10, primary': NOMBRE_MP10, 'MP10': NOMBRE_MP10,\n",
    "    'PM, primary': 'Material Particulado Total', 'Material particulado': 'Material Particulado Total',\n",
    "    'Toluene': 'Tolueno', 'Tolueno / metil benceno / Toluol / Fenilmetano': 'Tolueno',\n",
    "    'Benzene': 'Benceno',\n",
    "    'PCDD-F': 'Dibenzoparadioxinas policloradas y furanos (PCDD/F)',\n",
    "}\n",
    "\n",
    "MAPEO_ESTANDARIZACION_REGION = {\n",
    "    'Metropolitana de Santiago': 'Metropolitana', 'Región Metropolitana de Santiago': 'Metropolitana',\n",
    "    'Región del Gral. Carlos Ibáñez del Campo': 'Aysén',\n",
    "    'Aysen del General Carlos Ibanez del Campo': 'Aysén',\n",
    "    'Aysén del Gral. Carlos Ibañez del Campo': 'Aysén',\n",
    "    'Aysén del Gral. Carlos Ibáñez del Campo':'Aysén',\n",
    "    'Libertador Gral. Bernardo O Higgins': \"O'Higgins\", \"O'Higgins\": \"O'Higgins\",\n",
    "    'Libertador General Bernardo O Higgins': \"O'Higgins\",\n",
    "    \"Libertador Gral. Bernardo O'Higgins\":\"O'Higgins\",\n",
    "    'Nuble': 'Ñuble',\n",
    "    'Magallanes y de la Antártica Chilena':'Magallanes',\n",
    "    'Los Ríos': 'Los Ríos',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e24fa4c-3a5f-4d52-a0f5-c3dafce7e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8835599-a835-4c94-9545-4304c4013dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def cargar_y_preparar_datos(ruta_base, subcarpetas_fuentes, lista_años,\n",
    "                           mapa_contaminantes_est, mapa_regiones_est):\n",
    "    \"\"\"\n",
    "    Carga, renombra columnas, filtra, estandariza y unifica datos de emisiones.\n",
    "    Maneja archivos CSV (UTF-8/Latin-1) y Excel (.xlsx, .xls).\n",
    "    La lógica de renombrado de columnas está integrada en esta función.\n",
    "\n",
    "    Args:\n",
    "        ruta_base (str): Ruta al directorio principal de datos.\n",
    "        subcarpetas_fuentes (list): Lista de nombres de subcarpetas (fuentes como 'difusas').\n",
    "        lista_años (list): Lista de años (como strings) a procesar.\n",
    "        mapa_contaminantes_est (dict): Diccionario para estandarizar nombres de contaminantes.\n",
    "        mapa_regiones_est (dict): Diccionario para estandarizar nombres de regiones.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame or None: Un DataFrame unificado con datos estandarizados,\n",
    "                                  o None si ocurren errores críticos.\n",
    "    \"\"\"\n",
    "    todos_los_datos = []\n",
    "    # Definir los nombres de columna estándar en español\n",
    "    columnas_estandar = ['año', 'region', 'comuna', 'cantidad_toneladas', 'contaminante', 'origen_carpeta']\n",
    "    cols_esenciales = ['region', 'comuna', 'cantidad_toneladas', 'contaminante'] # Columnas que deben existir después de renombrar\n",
    "\n",
    "    for año_actual in lista_años:\n",
    "        for carpeta in subcarpetas_fuentes:\n",
    "            ruta_carpeta = os.path.join(ruta_base, carpeta)\n",
    "            if not os.path.isdir(ruta_carpeta):\n",
    "                print(f\"    Advertencia: Carpeta no encontrada: '{ruta_carpeta}'. Saltando.\")\n",
    "                continue\n",
    "            archivo_encontrado = None\n",
    "            try:\n",
    "                archivos_potenciales = [f for f in os.listdir(ruta_carpeta) if año_actual in f and f.lower().endswith(('.csv', '.xlsx', '.xls'))]\n",
    "                if archivos_potenciales:\n",
    "                    archivos_csv = [f for f in archivos_potenciales if f.lower().endswith('.csv')]\n",
    "                    if archivos_csv:\n",
    "                        archivo_encontrado = archivos_csv[0]\n",
    "                    else:\n",
    "                        archivo_encontrado = archivos_potenciales[0]\n",
    "            except FileNotFoundError:\n",
    "                print(f\"    Error: No se pudo acceder a la carpeta '{ruta_carpeta}'.\")\n",
    "                continue\n",
    "            except Exception as e_listar:\n",
    "                 print(f\"    Error al listar archivos en '{ruta_carpeta}': {e_listar}\")\n",
    "                 continue\n",
    "\n",
    "            if not archivo_encontrado:\n",
    "                print(f\"    INFO: No se encontró archivo para año {año_actual} en '{carpeta}'.\")\n",
    "                continue\n",
    "\n",
    "            ruta_archivo = os.path.join(ruta_carpeta, archivo_encontrado)\n",
    "            df_temporal = None\n",
    "            print(f\"    Leyendo archivo: '{archivo_encontrado}'\")\n",
    "\n",
    "            try:\n",
    "                if ruta_archivo.lower().endswith('.csv'):\n",
    "                    try:\n",
    "                       df_temporal = pd.read_csv(ruta_archivo, encoding='utf-8', sep=';', decimal=',', on_bad_lines='warn', low_memory=False)\n",
    "                    except UnicodeDecodeError:\n",
    "                       df_temporal = pd.read_csv(ruta_archivo, encoding='latin-1', sep=';', decimal=',', on_bad_lines='warn', low_memory=False)\n",
    "                    except Exception as error_csv:\n",
    "                         print(f\"      ERROR leyendo CSV: {type(error_csv).__name__} - {error_csv}\")\n",
    "                         continue # Saltar archivo\n",
    "                elif ruta_archivo.lower().endswith(('.xlsx', '.xls')):\n",
    "                     df_temporal = pd.read_excel(ruta_archivo, engine='openpyxl')\n",
    "            except Exception as error_lectura:\n",
    "                 print(f\"      ERROR: Falló la lectura del archivo. Error: {type(error_lectura).__name__} - {error_lectura}\")\n",
    "                 continue # Saltar archivo\n",
    "\n",
    "            if df_temporal is not None and not df_temporal.empty:\n",
    "                df_temporal.columns = df_temporal.columns.str.strip()\n",
    "\n",
    "                df_temporal['año'] = año_actual\n",
    "                df_temporal['origen_carpeta'] = carpeta # Añadir información de la fuente\n",
    "\n",
    "                dicc_renombrar = {}\n",
    "                if 'REGION' in df_temporal.columns: dicc_renombrar['REGION'] = 'region'\n",
    "                elif 'nom_region' in df_temporal.columns: dicc_renombrar['nom_region'] = 'region'\n",
    "                # Comuna\n",
    "                if 'NOM_COM' in df_temporal.columns: dicc_renombrar['NOM_COM'] = 'comuna'\n",
    "                elif 'Comuna_Ruta' in df_temporal.columns: dicc_renombrar['Comuna_Ruta'] = 'comuna'\n",
    "                # Contaminante\n",
    "                if 'codigo_parametro' in df_temporal.columns: dicc_renombrar['codigo_parametro'] = 'contaminante'\n",
    "                elif 'codigo_parameter' in df_temporal.columns: dicc_renombrar['codigo_parameter'] = 'contaminante'\n",
    "                elif 'codigo_contaminante_ruta' in df_temporal.columns: dicc_renombrar['codigo_contaminante_ruta'] = 'contaminante'\n",
    "                elif 'contaminantes' in df_temporal.columns: dicc_renombrar['contaminantes'] = 'contaminante' # Variación común\n",
    "                # Valor (asumiendo 'cantidad_toneladas' como el más común y ya estándar)\n",
    "                if 'cantidad_toneladas' not in df_temporal.columns:\n",
    "                     print(f\"      Advertencia: Columna 'cantidad_toneladas' no encontrada en {archivo_encontrado}. Verifique el archivo.\")\n",
    "                if dicc_renombrar:\n",
    "                    df_temporal.rename(columns=dicc_renombrar, inplace=True)\n",
    "                columnas_faltantes = [col for col in cols_esenciales if col not in df_temporal.columns]\n",
    "\n",
    "                if columnas_faltantes:\n",
    "                    print(f\"      ¡ERROR GRAVE! Faltan columnas estándar después del intento de renombrado: {columnas_faltantes}. Archivo: {archivo_encontrado}. Saltando.\")\n",
    "                    continue\n",
    "                try:\n",
    "                    columnas_std_faltantes = [sc for sc in columnas_estandar if sc not in df_temporal.columns]\n",
    "                    if columnas_std_faltantes:\n",
    "                         raise KeyError(f\"Columnas estándar faltantes antes de la selección final: {columnas_std_faltantes}\")\n",
    "                    df_temporal = df_temporal[columnas_estandar]\n",
    "                except KeyError as e:\n",
    "                    print(f\"      ¡ERROR GRAVE! No se pudieron seleccionar las columnas estándar finales. {e}. Archivo: {archivo_encontrado}. Saltando.\")\n",
    "                    continue\n",
    "\n",
    "                todos_los_datos.append(df_temporal)\n",
    "\n",
    "            elif df_temporal is not None and df_temporal.empty:\n",
    "                print(f\"      INFO: Archivo '{archivo_encontrado}' leído pero resultó vacío.\")\n",
    "\n",
    "    if not todos_los_datos:\n",
    "        print(\"\\nError Crítico: No se cargaron datos válidos de ninguna fuente.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\nUnificando datos de {len(todos_los_datos)} archivo(s)...\")\n",
    "    try:\n",
    "        df_unificado = pd.concat(todos_los_datos, ignore_index=True)\n",
    "    except Exception as error_concat:\n",
    "        print(f\"Error Crítico al concatenar DataFrames: {error_concat}\")\n",
    "        return None\n",
    "    print(f\"DataFrame unificado creado con {len(df_unificado)} filas iniciales.\")\n",
    "\n",
    "    df_unificado['año'] = df_unificado['año'].astype(str)\n",
    "    df_unificado['origen_carpeta'] = df_unificado['origen_carpeta'].astype(str)\n",
    "\n",
    "    try:\n",
    "        df_unificado['cantidad_toneladas'] = pd.to_numeric(df_unificado['cantidad_toneladas'], errors='coerce')\n",
    "    except Exception as e_numeric:\n",
    "        print(f\"Error inesperado al convertir 'cantidad_toneladas' a numérico: {e_numeric}\")\n",
    "        return None\n",
    "\n",
    "    columnas_para_dropna = ['año', 'region', 'comuna', 'cantidad_toneladas', 'contaminante']\n",
    "    filas_antes_nan = len(df_unificado)\n",
    "    df_unificado.dropna(subset=columnas_para_dropna, inplace=True)\n",
    "    filas_despues_nan = len(df_unificado)\n",
    "    print(f\"Limpieza: Se eliminaron {filas_antes_nan - filas_despues_nan} filas con valores nulos en columnas clave.\")\n",
    "\n",
    "    if df_unificado.empty:\n",
    "        print(\"Error: No quedan datos válidos después de la limpieza de NaNs.\")\n",
    "        return None\n",
    "        \n",
    "    print(\"Estandarizando nombres de Región, Comuna y Contaminante...\")\n",
    "    try:\n",
    "        df_unificado['region'] = df_unificado['region'].astype(str).str.strip()\n",
    "        df_unificado['region'] = df_unificado['region'].replace(mapa_regiones_est)\n",
    "        df_unificado['comuna'] = df_unificado['comuna'].astype(str).str.strip().str.title()\n",
    "        df_unificado['contaminante'] = df_unificado['contaminante'].astype(str).str.strip()\n",
    "        df_unificado['contaminante'] = df_unificado['contaminante'].apply(lambda x: mapa_contaminantes_est.get(x, x))\n",
    "        print(\"  Estandarización completada.\")\n",
    "    except Exception as e_std:\n",
    "        print(f\"Error inesperado durante la estandarización: {e_std}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"--- Preparación de Datos Finalizada ---\")\n",
    "    print(f\"DataFrame final listo con {len(df_unificado)} filas válidas.\")\n",
    "    return df_unificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "119b5208-a15d-4a85-ac89-684fae4e0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "239acaac-e49a-44ec-ad98-ff85805182ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def generar_grafico_contaminante_especifico(df, contaminante_a_filtrar, directorio_salida, año_grafico):\n",
    "    try:\n",
    "        contaminante_mayuscula = contaminante_a_filtrar.upper()\n",
    "        df_filtrado = df[df['contaminante'].astype(str).str.upper() == contaminante_mayuscula].copy()\n",
    "\n",
    "        if df_filtrado.empty:\n",
    "            print(f\"  INFO ({año_grafico}): No se encontraron datos para '{contaminante_a_filtrar}'.\")\n",
    "            return\n",
    "\n",
    "        datos_agrupados = df_filtrado.groupby(['region', 'origen_carpeta'])['cantidad_toneladas'].sum()\n",
    "        df_grafico = datos_agrupados.unstack(level='origen_carpeta', fill_value=0)\n",
    "        df_grafico = df_grafico.loc[df_grafico.sum(axis=1) > 1e-6].sort_index()\n",
    "\n",
    "        if df_grafico.empty:\n",
    "            print(f\"  INFO ({año_grafico}): No hay emisiones significativas de '{contaminante_a_filtrar}' para graficar.\")\n",
    "            return\n",
    "\n",
    "        ax = df_grafico.plot(kind='bar', stacked=False, figsize=(18, 8), width=0.8, colormap='tab10')\n",
    "        plt.title(f'Emisiones de {contaminante_a_filtrar} por Región y Fuente ({año_grafico})', fontsize=16)\n",
    "        plt.xlabel('Región', fontsize=12)\n",
    "        plt.ylabel('Suma Total (Toneladas)', fontsize=12) # Etiqueta genérica\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.legend(title='Tipo de Fuente')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        nombre_cont_limpio = \"\".join(c if c.isalnum() else \"_\" for c in contaminante_a_filtrar)\n",
    "        nombre_archivo = f'grafico_ABS_{nombre_cont_limpio}_region_fuente_{año_grafico}.png'\n",
    "        ruta_guardado = os.path.join(directorio_salida, nombre_archivo)\n",
    "        plt.savefig(ruta_guardado, dpi=100)\n",
    "        plt.close()\n",
    "\n",
    "    except KeyError as ke:\n",
    "        print(f\"  ¡ERROR de Clave ({año_grafico})! Graf. Absoluto '{contaminante_a_filtrar}'. Columna faltante: {ke}. Asegúrese que las columnas estándar existen.\")\n",
    "    except Exception as e_plot:\n",
    "        print(f\"  ¡ERROR Inesperado ({año_grafico})! Graf. Absoluto '{contaminante_a_filtrar}': {type(e_plot).__name__} - {e_plot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5150aee-861d-4cff-8ab4-fe1455dcd727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafico_proporcion(df, contaminante_a_filtrar, directorio_salida, año_grafico):\n",
    "    try:\n",
    "        contaminante_mayuscula = contaminante_a_filtrar.upper()\n",
    "        # Filtrar usando columna estándar 'contaminante'\n",
    "        df_filtrado = df[df['contaminante'].astype(str).str.upper() == contaminante_mayuscula].copy()\n",
    "\n",
    "        if df_filtrado.empty:\n",
    "            print(f\"  INFO ({año_grafico}): No se encontraron datos para '{contaminante_a_filtrar}'.\")\n",
    "            return\n",
    "\n",
    "        datos_agrupados = df_filtrado.groupby(['region', 'origen_carpeta'])['cantidad_toneladas'].sum()\n",
    "        datos_agrupados = datos_agrupados[datos_agrupados > 1e-9]\n",
    "\n",
    "        if datos_agrupados.empty:\n",
    "             print(f\"  INFO ({año_grafico}): No hay emisiones positivas para calcular proporciones de '{contaminante_a_filtrar}'.\")\n",
    "             return\n",
    "\n",
    "        datos_porcentaje = datos_agrupados.groupby(level='region', group_keys=False).apply(lambda x: 100 * x / float(x.sum()))\n",
    "        df_grafico = datos_porcentaje.unstack(level='origen_carpeta', fill_value=0)\n",
    "        df_grafico = df_grafico.loc[df_grafico.sum(axis=1) > 1e-6].sort_index()\n",
    "\n",
    "        if df_grafico.empty:\n",
    "            print(f\"  INFO ({año_grafico}): No hay datos significativos para proporciones de '{contaminante_a_filtrar}'.\")\n",
    "            return\n",
    "\n",
    "        \n",
    "        ax = df_grafico.plot(kind='bar', stacked=True, figsize=(18, 8), width=0.8, colormap='tab10')\n",
    "        plt.title(f'Proporción de Fuentes de {contaminante_a_filtrar} por Región ({año_grafico})', fontsize=16)\n",
    "        plt.xlabel('Región', fontsize=12)\n",
    "        plt.ylabel('Porcentaje (%)', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "        plt.yticks(np.arange(0, 101, 10), fontsize=10)\n",
    "        plt.ylim(0, 100)\n",
    "        plt.axhline(50, color='grey', linestyle='--', linewidth=0.8)\n",
    "        plt.legend(title='Tipo de Fuente', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "        plt.tight_layout(rect=[0, 0, 0.9, 1]) # Ajustar layout para leyenda\n",
    "\n",
    "        nombre_cont_limpio = \"\".join(c if c.isalnum() else \"_\" for c in contaminante_a_filtrar)\n",
    "        nombre_archivo = f'grafico_PROP_{nombre_cont_limpio}_region_fuente_{año_grafico}.png'\n",
    "        ruta_guardado = os.path.join(directorio_salida, nombre_archivo)\n",
    "        plt.savefig(ruta_guardado, bbox_inches='tight', dpi=100) # Usar bbox_inches='tight'\n",
    "        plt.close()\n",
    "\n",
    "    except KeyError as ke:\n",
    "         print(f\"  ¡ERROR de Clave ({año_grafico})! Graf. Proporción '{contaminante_a_filtrar}'. Columna faltante: {ke}. Asegúrese que las columnas estándar existen.\")\n",
    "    except ZeroDivisionError:\n",
    "         print(f\"  ¡ERROR ({año_grafico})! División por cero al calcular % para '{contaminante_a_filtrar}'. Revise si hay regiones con suma total cero.\")\n",
    "    except Exception as e_plot:\n",
    "         print(f\"  ¡ERROR Inesperado ({año_grafico})! Graf. Proporción '{contaminante_a_filtrar}': {type(e_plot).__name__} - {e_plot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3035cbb-27f6-4369-a65d-7f7b2c2ff151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def generar_grafico_contaminantes_ciudad(df, nombre_ciudad, top_n, directorio_salida, año_grafico):\n",
    "    \"\"\"Genera gráfico de barras con Top N contaminantes para una ciudad/comuna y AÑO.\"\"\"\n",
    "    try:\n",
    "        ciudad_a_buscar = nombre_ciudad.title()\n",
    "        df_ciudad = df[df['comuna'].astype(str) == ciudad_a_buscar].copy()\n",
    "\n",
    "        if df_ciudad.empty:\n",
    "            print(f\"  INFO ({año_grafico}): No se encontraron datos para '{nombre_ciudad}' (buscada como '{ciudad_a_buscar}').\")\n",
    "            return\n",
    "\n",
    "        df_ciudad['cantidad_toneladas'] = pd.to_numeric(df_ciudad['cantidad_toneladas'], errors='coerce')\n",
    "        df_ciudad.dropna(subset=['cantidad_toneladas', 'contaminante'], inplace=True)\n",
    "\n",
    "        if df_ciudad.empty:\n",
    "            print(f\"  INFO ({año_grafico}): No quedan datos numéricos válidos para '{nombre_ciudad}' después de limpiar NaNs.\")\n",
    "            return\n",
    "\n",
    "        suma_cont_ciudad = df_ciudad.groupby('contaminante')['cantidad_toneladas'].sum()\n",
    "        suma_cont_ciudad = suma_cont_ciudad[suma_cont_ciudad > 1e-9]\n",
    "\n",
    "        if suma_cont_ciudad.empty:\n",
    "            print(f\"  INFO ({año_grafico}): No hay emisiones positivas registradas para contaminantes en '{nombre_ciudad}'.\")\n",
    "            return\n",
    "\n",
    "        n_real = min(top_n, len(suma_cont_ciudad))\n",
    "        if n_real == 0:\n",
    "             print(f\"  INFO ({año_grafico}): No hay datos de contaminantes > 0 para graficar.\")\n",
    "             return\n",
    "        suma_top_ciudad = suma_cont_ciudad.nlargest(n_real)\n",
    "\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        colores = sns.color_palette(\"viridis\", n_colors=n_real)\n",
    "        suma_top_ciudad.sort_values(ascending=False).plot(kind='bar', color=colores)\n",
    "        plt.title(f'Top {n_real} Contaminantes Emitidos en {nombre_ciudad} ({año_grafico})', fontsize=15)\n",
    "        plt.xlabel('Contaminante', fontsize=12)\n",
    "        plt.ylabel('Emisiones Totales (toneladas)', fontsize=12) # Asumiendo unidad\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.tight_layout() # Ajustar layout\n",
    "\n",
    "        nombre_ciudad_limpio = \"\".join(c if c.isalnum() else \"_\" for c in nombre_ciudad)\n",
    "        nombre_archivo = f'grafico_top{n_real}_contaminantes_{nombre_ciudad_limpio}_{año_grafico}.png'\n",
    "        ruta_guardado = os.path.join(directorio_salida, nombre_archivo)\n",
    "        plt.savefig(ruta_guardado, dpi=100)\n",
    "        plt.close()\n",
    "\n",
    "    except KeyError as ke:\n",
    "        print(f\"  ¡ERROR de Clave ({año_grafico})! Graf. Ciudad '{nombre_ciudad}'. Columna faltante: {ke}. Asegúrese que las columnas 'comuna', 'cantidad_toneladas', 'contaminante' existen.\")\n",
    "    except Exception as e_plot:\n",
    "        print(f\"  ¡ERROR Inesperado ({año_grafico})! Graf. Ciudad '{nombre_ciudad}': {type(e_plot).__name__} - {e_plot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac75f1-fc5f-41d7-93e5-ac1a0d7dae23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b04e70-bec8-4ea6-bb68-f2c9638cca1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de gráficos: 'graficos_2019-2023_reporte_es'\n",
      "    Leyendo archivo: 'ruea-efd-2019-ckan.csv'\n",
      "    Leyendo archivo: 'ruea-efp-2019-ckan.csv'\n",
      "    Leyendo archivo: 'ruea-tr-2019-ckan.csv'\n",
      "    Leyendo archivo: 'ruea-efd-2020-ckan.csv'\n",
      "    Leyendo archivo: 'ruea-efp-2020-ckan.csv'\n",
      "    Leyendo archivo: 'ruea-tr-2020-ckan.csv'\n",
      "    Leyendo archivo: 'ruea-efd-2021-ckan.csv'\n",
      "    Leyendo archivo: 'ruea-efp-2021-ckan.xlsx'\n",
      "    Leyendo archivo: 'ruea-tr-2021-ckan.csv'\n",
      "    Leyendo archivo: 'ruea-efd-2022-ckan.csv'\n",
      "    Leyendo archivo: 'ruea-efp-2022-ckan.csv'\n",
      "    Leyendo archivo: 'ruea-tr-2022-ckan.csv'\n",
      "    Leyendo archivo: 'ruea-efd-2023-ckan.csv'\n",
      "    Leyendo archivo: 'ruea-efp-2023-ckan.csv'\n",
      "    Leyendo archivo: 'ruea-tr-2023-ckan.csv'\n",
      "\n",
      "Unificando datos de 15 archivo(s)...\n",
      "DataFrame unificado creado con 5398387 filas iniciales.\n",
      "Limpieza: Se eliminaron 175339 filas con valores nulos en columnas clave.\n",
      "Estandarizando nombres de Región, Comuna y Contaminante...\n",
      "  Estandarización completada.\n",
      "--- Preparación de Datos Finalizada ---\n",
      "DataFrame final listo con 5223048 filas válidas.\n",
      "\n",
      "--- FIN: Ejecución del Análisis Multi-Año (2019, 2020, 2021, 2022, 2023) ---\n",
      "Revisa los gráficos generados en la carpeta: 'graficos_2019-2023_reporte_es'\n"
     ]
    }
   ],
   "source": [
    "datos_unificados = None\n",
    "try:\n",
    "    os.makedirs(CARPETA_GRAFICOS, exist_ok=True)\n",
    "    print(f\"Directorio de gráficos: '{CARPETA_GRAFICOS}'\")\n",
    "except OSError as e:\n",
    "    print(f\"Error Fatal: No se pudo crear el directorio de gráficos '{CARPETA_GRAFICOS}'. Error: {e}\")\n",
    "else:\n",
    "    datos_unificados = cargar_y_preparar_datos(\n",
    "        RUTA_BASE_DATOS, SUBCARPETAS, AÑOS_A_PROCESAR,\n",
    "        MAPA_CONTAMINANTES,\n",
    "        MAPEO_ESTANDARIZACION_REGION\n",
    "    )\n",
    "\n",
    "# --- 2. Generar Gráficos (si la carga de datos fue exitosa) ---\n",
    "if datos_unificados is not None and not datos_unificados.empty:\n",
    "    años_en_datos = sorted(datos_unificados['año'].unique())\n",
    "    for año_actual_grafico in años_en_datos:\n",
    "        df_año = datos_unificados[datos_unificados['año'] == año_actual_grafico]\n",
    "        if df_año.empty:\n",
    "            continue\n",
    "\n",
    "        generar_grafico_contaminante_especifico(df_año, NOMBRE_MP25, CARPETA_GRAFICOS, año_actual_grafico)\n",
    "        grafico_proporcion(df_año, NOMBRE_MP25, CARPETA_GRAFICOS, año_actual_grafico)\n",
    "        generar_grafico_contaminante_especifico(df_año, NOMBRE_MP10, CARPETA_GRAFICOS, año_actual_grafico)\n",
    "        grafico_proporcion(df_año, NOMBRE_MP10, CARPETA_GRAFICOS, año_actual_grafico)\n",
    "        generar_grafico_contaminantes_ciudad(df_año,NOMBRE_CIUDAD_FILTRO,TOP_N_CONTAMINANTES_CIUDAD,CARPETA_GRAFICOS,año_actual_grafico)\n",
    "        \n",
    "elif datos_unificados is None:\n",
    "     print(\"No hay df unificado\")\n",
    "\n",
    "# --- Mensaje Final ---\n",
    "print(f\"\\n--- FIN: Ejecución del Análisis Multi-Año ({', '.join(AÑOS_A_PROCESAR)}) ---\")\n",
    "# Verificar si el directorio existe y contiene gráficos\n",
    "if os.path.exists(CARPETA_GRAFICOS):\n",
    "    try:\n",
    "        if any(fname.endswith('.png') for fname in os.listdir(CARPETA_GRAFICOS)):\n",
    "            print(f\"Revisa los gráficos generados en la carpeta: '{CARPETA_GRAFICOS}'\")\n",
    "        else:\n",
    "             print(f\"Se creó la carpeta '{CARPETA_GRAFICOS}', pero no contiene archivos PNG generados.\")\n",
    "    except Exception as e_list_final:\n",
    "        print(f\"No se pudo verificar el contenido de la carpeta de gráficos: {e_list_final}\")\n",
    "else:\n",
    "     print(f\"No se generaron gráficos (posiblemente debido a errores previos o directorio no creado).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "987892ea-6089-4ee4-8ca6-161fe43d1135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Revision de daros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a93f0a7-457a-44bb-acd8-62b793c1b99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forma del DataFrame (filas, columnas): (5223048, 6)\n",
      "\n",
      "Primeras 5 filas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>año</th>\n",
       "      <th>region</th>\n",
       "      <th>comuna</th>\n",
       "      <th>cantidad_toneladas</th>\n",
       "      <th>contaminante</th>\n",
       "      <th>origen_carpeta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>Antofagasta</td>\n",
       "      <td>Antofagasta</td>\n",
       "      <td>3.037223</td>\n",
       "      <td>Carbono Negro</td>\n",
       "      <td>difusas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>Antofagasta</td>\n",
       "      <td>Mejillones</td>\n",
       "      <td>0.104612</td>\n",
       "      <td>Carbono Negro</td>\n",
       "      <td>difusas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>Antofagasta</td>\n",
       "      <td>Sierra Gorda</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>Carbono Negro</td>\n",
       "      <td>difusas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>Antofagasta</td>\n",
       "      <td>Taltal</td>\n",
       "      <td>0.098901</td>\n",
       "      <td>Carbono Negro</td>\n",
       "      <td>difusas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>Antofagasta</td>\n",
       "      <td>Calama</td>\n",
       "      <td>1.361261</td>\n",
       "      <td>Carbono Negro</td>\n",
       "      <td>difusas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    año       region        comuna  cantidad_toneladas   contaminante  \\\n",
       "0  2019  Antofagasta   Antofagasta            3.037223  Carbono Negro   \n",
       "1  2019  Antofagasta    Mejillones            0.104612  Carbono Negro   \n",
       "2  2019  Antofagasta  Sierra Gorda            0.012500  Carbono Negro   \n",
       "3  2019  Antofagasta        Taltal            0.098901  Carbono Negro   \n",
       "4  2019  Antofagasta        Calama            1.361261  Carbono Negro   \n",
       "\n",
       "  origen_carpeta  \n",
       "0        difusas  \n",
       "1        difusas  \n",
       "2        difusas  \n",
       "3        difusas  \n",
       "4        difusas  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Información General (Tipos de datos, Nulos):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5223048 entries, 0 to 5398386\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   año                 object \n",
      " 1   region              object \n",
      " 2   comuna              object \n",
      " 3   cantidad_toneladas  float64\n",
      " 4   contaminante        object \n",
      " 5   origen_carpeta      object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 278.9+ MB\n",
      "\n",
      "Estadísticas descriptivas para 'cantidad_toneladas':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    5,223,048.00\n",
       "mean           122.31\n",
       "std         11,826.29\n",
       "min           -518.24\n",
       "25%              0.00\n",
       "50%              0.01\n",
       "75%              0.35\n",
       "max      7,648,811.43\n",
       "Name: cantidad_toneladas, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ADVERTENCIA: Se encontraron 178 registros con valores negativos en 'cantidad_toneladas'.\n",
      "\n",
      "Valores Únicos en columnas clave:\n",
      "- Columna 'region': 16 valores únicos.\n",
      "  Valores: ['Antofagasta', 'Araucanía', 'Arica y Parinacota', 'Atacama', 'Aysén', 'Biobío', 'Coquimbo', 'Los Lagos', 'Los Ríos', 'Magallanes', 'Maule', 'Metropolitana', \"O'Higgins\", 'Tarapacá', 'Valparaíso', 'Ñuble']\n",
      "- Columna 'contaminante': 20 valores únicos.\n",
      "  Valores: ['Amoniaco (NH3)', 'Arsénico', 'Benceno', 'COV', 'Carbono Negro', 'Dibenzoparadioxinas policloradas y furanos (PCDD/F)', 'Dióxido de azufre (SO2)', 'Dióxido de carbono (CO2)', 'Hidrocarburos totales', 'MP10', 'MP2.5', 'Material Particulado Total', 'Mercurio', 'Metano (CH4)', 'Monóxido de carbono (CO)', 'NOx', 'Oxido Nitroso', 'Plomo', 'SOx', 'Tolueno']\n",
      "- Columna 'origen_carpeta': 3 valores únicos.\n",
      "  Valores: ['difusas', 'puntuales', 'ruta']\n",
      "\n",
      "¿Está la ciudad 'Valdivia' (buscada como 'Valdivia') presente en 'comuna'?: Sí\n"
     ]
    }
   ],
   "source": [
    "if 'datos_unificados' in locals() and datos_unificados is not None and not datos_unificados.empty:\n",
    "    print(f\"\\nForma del DataFrame (filas, columnas): {datos_unificados.shape}\")\n",
    "    print(\"\\nPrimeras 5 filas:\")\n",
    "    from IPython.display import display\n",
    "    display(datos_unificados.head())\n",
    "\n",
    "    print(\"\\nInformación General (Tipos de datos, Nulos):\")\n",
    "    datos_unificados.info()\n",
    "\n",
    "    if 'cantidad_toneladas' in datos_unificados.columns and pd.api.types.is_numeric_dtype(datos_unificados['cantidad_toneladas']):\n",
    "        print(f\"\\nEstadísticas descriptivas para 'cantidad_toneladas':\")\n",
    "        display(datos_unificados['cantidad_toneladas'].describe().apply(\"{:,.2f}\".format))\n",
    "        # Check for negative values which might indicate data issues\n",
    "        if (datos_unificados['cantidad_toneladas'] < 0).any():\n",
    "             neg_count = (datos_unificados['cantidad_toneladas'] < 0).sum()\n",
    "             print(f\"  ADVERTENCIA: Se encontraron {neg_count} registros con valores negativos en 'cantidad_toneladas'.\")\n",
    "    else:\n",
    "        print(\"\\nColumna 'cantidad_toneladas' no es numérica o no existe, no se muestran estadísticas descriptivas.\")\n",
    "\n",
    "    print(\"\\nValores Únicos en columnas clave:\")\n",
    "    columnas_clave_preview = ['region', 'contaminante', 'origen_carpeta']\n",
    "    for col in columnas_clave_preview:\n",
    "        if col in datos_unificados.columns:\n",
    "            try:\n",
    "                num_unicos = datos_unificados[col].nunique()\n",
    "                print(f\"- Columna '{col}': {num_unicos} valores únicos.\")\n",
    "                all_uniques = sorted(datos_unificados[col].unique())\n",
    "                if num_unicos < 25:\n",
    "                    print(f\"  Valores: {all_uniques}\")\n",
    "                else: # Show a sample\n",
    "                    print(f\"  Muestra: {all_uniques[:10]}... (y {num_unicos-10} más)\")\n",
    "            except Exception as e_unique:\n",
    "                 print(f\"  Error al obtener únicos para '{col}': {e_unique}\")\n",
    "        else:\n",
    "             print(f\"- Advertencia: No se encontró la columna '{col}'.\")\n",
    "\n",
    "    # Specific check for the target city filter ('comuna')\n",
    "    if 'comuna' in datos_unificados.columns:\n",
    "        ciudad_filtrar_title = NOMBRE_CIUDAD_FILTRO.title()\n",
    "        try:\n",
    "            comunas_unicas = datos_unificados['comuna'].unique()\n",
    "            ciudad_presente = ciudad_filtrar_title in comunas_unicas\n",
    "            print(f\"\\n¿Está la ciudad '{NOMBRE_CIUDAD_FILTRO}' (buscada como '{ciudad_filtrar_title}') presente en 'comuna'?: {'Sí' if ciudad_presente else 'NO'}\")\n",
    "        except Exception as e_comuna:\n",
    "             print(f\"\\nError al verificar la ciudad '{NOMBRE_CIUDAD_FILTRO}': {e_comuna}\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd9c2db1-341d-4727-95b4-d3de0efe371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis macrozonas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61d02b48-665f-4ec5-bc8c-eb3d94861bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Análisis Descriptivo por Macrozonas ---\n",
      "1. Definiendo y aplicando Macrozonas...\n",
      "\n",
      "2. Filtrando por contaminantes: MP2.5, MP10, Dióxido de azufre (SO2), Monóxido de carbono (CO)\n",
      "\n",
      "3. Calculando emisiones anuales agrupadas por Macrozona y Contaminante...\n",
      "  Se calcularon 80 registros anuales agrupados.\n",
      "\n",
      "4. Generando Gráfico: Boxplot de Emisiones Anuales por Macrozona (Escala Log)...\n",
      "  -> Gráfico Boxplot guardado en: 'graficos_2019-2023_reporte_es/grafico_boxplot_emisiones_macrozona_log_2019-2023.png'\n",
      "  Cálculo de porcentajes promedio completado.\n",
      "\n",
      "6. Generando Gráfico: Barras de Contribución % Promedio Fuentes (MP2.5)...\n",
      "  -> Gráfico Barras % guardado en: 'graficos_2019-2023_reporte_es/grafico_barras_pct_fuente_mp25_macrozona_2019-2023.png'\n"
     ]
    }
   ],
   "source": [
    "# Verificar si existen los datos\n",
    "if 'datos_unificados' not in locals() or datos_unificados is None or datos_unificados.empty:\n",
    "    print(\"Error: El DataFrame 'datos_unificados' no está disponible o está vacío. No se puede realizar el análisis.\")\n",
    "else:\n",
    "    # --- 1. Definir y Aplicar Macrozonas ---\n",
    "    print(\"1. Definiendo y aplicando Macrozonas...\")\n",
    "    # Usar nombres de región ya estandarizados\n",
    "    mapa_regiones_macrozonas = {\n",
    "        'Arica y Parinacota': 'Norte', 'Tarapacá': 'Norte', 'Antofagasta': 'Norte',\n",
    "        'Atacama': 'Norte', 'Coquimbo': 'Norte',\n",
    "        'Valparaíso': 'Centro', 'Metropolitana': 'Centro', \"O'Higgins\": 'Centro',\n",
    "        'Maule': 'Centro', 'Ñuble': 'Centro', 'Biobío': 'Centro',\n",
    "        'Araucanía': 'Sur', 'Los Ríos': 'Sur', 'Los Lagos': 'Sur',\n",
    "        'Aysén': 'Austral',\n",
    "        'Magallanes': 'Austral'\n",
    "    }\n",
    "    datos_analisis = datos_unificados.copy()\n",
    "    datos_analisis['macrozona'] = datos_analisis['region'].map(mapa_regiones_macrozonas)\n",
    "    regiones_no_mapeadas = datos_analisis[datos_analisis['macrozona'].isnull()]['region'].unique()\n",
    "    if len(regiones_no_mapeadas) > 0:\n",
    "        print(f\"  Advertencia: Las siguientes regiones no fueron mapeadas a una macrozona: {list(regiones_no_mapeadas)}\")\n",
    "        datos_analisis.dropna(subset=['macrozona'], inplace=True)\n",
    "        print(f\"  Registros de {len(regiones_no_mapeadas)} regiones no mapeadas excluidos del análisis.\")\n",
    "\n",
    "    contaminantes_macrozona = [NOMBRE_MP25, NOMBRE_MP10, 'Dióxido de azufre (SO2)', 'Monóxido de carbono (CO)']\n",
    "    print(f\"\\n2. Filtrando por contaminantes: {', '.join(contaminantes_macrozona)}\")\n",
    "    df_filtrado_cont = datos_analisis[datos_analisis['contaminante'].isin(contaminantes_macrozona)]\n",
    "\n",
    "    if df_filtrado_cont.empty:\n",
    "            print(\"  Error: No se encontraron datos para los contaminantes seleccionados en este análisis.\")\n",
    "    else:\n",
    "        # --- 3. Calcular Emisiones Anuales por Macrozona/Contaminante ---\n",
    "        print(\"\\n3. Calculando emisiones anuales agrupadas por Macrozona y Contaminante...\")\n",
    "        emisiones_anuales = df_filtrado_cont.groupby(['macrozona', 'año', 'contaminante'])['cantidad_toneladas'].sum().reset_index()\n",
    "        print(f\"  Se calcularon {len(emisiones_anuales)} registros anuales agrupados.\")\n",
    "\n",
    "        if not emisiones_anuales.empty:\n",
    "            # --- 4. Gráfico 1: Boxplot de Emisiones Anuales ---\n",
    "            print(\"\\n4. Generando Gráfico: Boxplot de Emisiones Anuales por Macrozona (Escala Log)...\")\n",
    "            plt.figure(figsize=(18, 9))\n",
    "            eje_caja = sns.boxplot(data=emisiones_anuales,\n",
    "                                 x='contaminante', y='cantidad_toneladas',\n",
    "                                 hue='macrozona', order=contaminantes_macrozona,\n",
    "                                 hue_order=['Norte', 'Centro', 'Sur', 'Austral'], palette='viridis', linewidth=1.5)\n",
    "            plt.title('Distribución de Emisiones Anuales por Macrozona y Contaminante (2019-2023)', fontsize=18, pad=20)\n",
    "            plt.xlabel('Contaminante', fontsize=14)\n",
    "            plt.ylabel('Emisiones Totales Anuales (toneladas, escala log)', fontsize=14)\n",
    "            plt.yscale('log')\n",
    "            try:\n",
    "                 eje_caja.yaxis.set_major_formatter(mticker.ScalarFormatter())\n",
    "                 eje_caja.yaxis.get_major_formatter().set_scientific(False)\n",
    "                 eje_caja.yaxis.get_major_formatter().set_useOffset(False)\n",
    "            except Exception as error_formato:\n",
    "                 print(f\"   Advertencia: No se pudo aplicar formato especial al eje Y log: {error_formato}\")\n",
    "            plt.xticks(fontsize=12); plt.yticks(fontsize=12)\n",
    "            plt.legend(title='Macrozona', fontsize=12, title_fontsize=13)\n",
    "            plt.tight_layout()\n",
    "            nombre_archivo_caja = f'grafico_boxplot_emisiones_macrozona_log_{AÑOS_A_PROCESAR[0]}-{AÑOS_A_PROCESAR[-1]}.png'\n",
    "            ruta_guardado_caja = os.path.join(CARPETA_GRAFICOS, nombre_archivo_caja)\n",
    "            try:\n",
    "                plt.savefig(ruta_guardado_caja, dpi=120)\n",
    "                print(f\"  -> Gráfico Boxplot guardado en: '{ruta_guardado_caja}'\")\n",
    "            except Exception as e_guardar: print(f\"  Error al guardar Boxplot: {e_guardar}\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            print(\"  No hay datos de emisiones anuales agrupadas para generar el boxplot.\")\n",
    "\n",
    "        df_mp25 = datos_analisis[datos_analisis['contaminante'] == NOMBRE_MP25]\n",
    "        if not df_mp25.empty:\n",
    "            suma_fuente = df_mp25.groupby(['macrozona', 'año', 'origen_carpeta'])['cantidad_toneladas'].sum()\n",
    "            total_año = suma_fuente.groupby(level=['macrozona', 'año']).transform('sum')\n",
    "            porcentaje_fuente = (suma_fuente / total_año.replace(0, np.nan)) * 100\n",
    "            porcentaje_fuente = porcentaje_fuente.dropna()\n",
    "            if not porcentaje_fuente.empty:\n",
    "                 pct_promedio_fuente = porcentaje_fuente.groupby(level=['macrozona', 'origen_carpeta']).mean().reset_index()\n",
    "                 pct_promedio_fuente.rename(columns={'cantidad_toneladas': 'porcentaje_promedio'}, inplace=True)\n",
    "                 plt.figure(figsize=(14, 8))\n",
    "                 eje_barra = sns.barplot(data=pct_promedio_fuente, x='macrozona', y='porcentaje_promedio',\n",
    "                                      hue='origen_carpeta', order=['Norte', 'Centro', 'Sur', 'Austral'],\n",
    "                                      hue_order=['difusas', 'puntuales', 'ruta'], palette='Set2', edgecolor='black', linewidth=0.8)\n",
    "                 plt.title(f'Contribución Promedio (%) de Fuentes a Emisiones {NOMBRE_MP25} por Macrozona (2019-2023)', fontsize=16, pad=20)\n",
    "                 plt.xlabel('Macrozona', fontsize=14)\n",
    "                 plt.ylabel('Contribución Promedio Anual (%)', fontsize=14)\n",
    "                 plt.xticks(fontsize=12); plt.yticks(np.arange(0, 101, 10), fontsize=12)\n",
    "                 plt.ylim(0, 100)\n",
    "                 plt.legend(title='Tipo de Fuente', fontsize=12, title_fontsize=13)\n",
    "                 plt.tight_layout()\n",
    "                 nombre_archivo_barra = f'grafico_barras_pct_fuente_mp25_macrozona_{AÑOS_A_PROCESAR[0]}-{AÑOS_A_PROCESAR[-1]}.png'\n",
    "                 ruta_guardado_barra = os.path.join(CARPETA_GRAFICOS, nombre_archivo_barra)\n",
    "                 try:\n",
    "                     plt.savefig(ruta_guardado_barra, dpi=120)\n",
    "                     print(f\"  -> Gráfico Barras % guardado en: '{ruta_guardado_barra}'\")\n",
    "                 except Exception as e_guardar: print(f\"  Error al guardar Gráfico Barras %: {e_guardar}\")\n",
    "                 plt.close()\n",
    "        else:\n",
    "             print(f\"  No se encontraron datos de {NOMBRE_MP25} para calcular la contribución de fuentes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d77c093-7893-4cfc-be28-cfc22653d516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generando Gráficos de Tendencia para MP2.5 (Separados por Fuente) ---\n",
      "Orden de regiones determinado por emisión total de MP2.5.\n",
      "Fuentes a graficar: ['difusas', 'puntuales', 'ruta']\n",
      "\n",
      "-- Generando gráfico para Fuente: 'difusas' | Contaminante: MP2.5 --\n",
      "  -> Gráfico guardado en: 'graficos_2019-2023_reporte_es/grafico_tendencia_MP2.5_region_año_FUENTE_difusas_2019-2023.png'\n",
      "\n",
      "-- Generando gráfico para Fuente: 'puntuales' | Contaminante: MP2.5 --\n",
      "  -> Gráfico guardado en: 'graficos_2019-2023_reporte_es/grafico_tendencia_MP2.5_region_año_FUENTE_puntuales_2019-2023.png'\n",
      "\n",
      "-- Generando gráfico para Fuente: 'ruta' | Contaminante: MP2.5 --\n",
      "  -> Gráfico guardado en: 'graficos_2019-2023_reporte_es/grafico_tendencia_MP2.5_region_año_FUENTE_ruta_2019-2023.png'\n",
      "\n",
      "--- Fin de la Generación de Gráficos de Tendencia por Fuente ---\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(f\"--- Generando Gráficos de Tendencia para {NOMBRE_MP25} (Separados por Fuente) ---\")\n",
    "\n",
    "if 'datos_unificados' not in locals() or datos_unificados is None or datos_unificados.empty:\n",
    "    print(\"Error: El DataFrame 'datos_unificados' no está disponible o está vacío. No se puede generar este gráfico.\")\n",
    "else:\n",
    "    # --- Preparación ---\n",
    "    lista_años_ordenada = sorted(datos_unificados['año'].unique())\n",
    "    fuentes_a_graficar = sorted(datos_unificados['origen_carpeta'].unique())\n",
    "\n",
    "    # Determinar orden de regiones basado en emisión total de MP2.5\n",
    "    try:\n",
    "        orden_regiones = datos_unificados[datos_unificados['contaminante'] == NOMBRE_MP25]\\\n",
    "                             .groupby('region')['cantidad_toneladas'].sum()\\\n",
    "                             .sort_values(ascending=False).index.tolist()\n",
    "        print(f\"Orden de regiones determinado por emisión total de {NOMBRE_MP25}.\")\n",
    "    except KeyError:\n",
    "        print(f\"Advertencia: No se pudo calcular el orden de regiones. Usando orden alfabético.\")\n",
    "        orden_regiones = sorted(datos_unificados['region'].unique())\n",
    "\n",
    "    print(f\"Fuentes a graficar: {fuentes_a_graficar}\")\n",
    "\n",
    "    # --- Bucle para cada tipo de fuente ---\n",
    "    for fuente_actual in fuentes_a_graficar:\n",
    "        print(f\"\\n-- Generando gráfico para Fuente: '{fuente_actual}' | Contaminante: {NOMBRE_MP25} --\")\n",
    "\n",
    "        # Filtrar datos para la fuente actual Y MP2.5\n",
    "        df_fuente_mp25 = datos_unificados[\n",
    "            (datos_unificados['origen_carpeta'] == fuente_actual) &\n",
    "            (datos_unificados['contaminante'] == NOMBRE_MP25)\n",
    "        ]\n",
    "\n",
    "        if not df_fuente_mp25.empty:\n",
    "            datos_grafico = df_fuente_mp25.groupby(['region', 'año'])['cantidad_toneladas'].sum().reset_index()\n",
    "\n",
    "            if datos_grafico.empty:\n",
    "                print(f\"  INFO: No hay datos agregados para graficar para la fuente '{fuente_actual}'.\")\n",
    "                continue\n",
    "\n",
    "            plt.figure(figsize=(18, 8))\n",
    "            ax = sns.barplot(data=datos_grafico,\n",
    "                             x='region', y='cantidad_toneladas', hue='año',\n",
    "                             order=orden_regiones,\n",
    "                             hue_order=lista_años_ordenada,\n",
    "                             palette='viridis'\n",
    "                            )\n",
    "\n",
    "            plt.title(f'Emisiones Totales de {NOMBRE_MP25} (Fuente: {fuente_actual.capitalize()}) por Región y Año', fontsize=16, pad=15)\n",
    "            plt.xlabel('Región', fontsize=13)\n",
    "            plt.ylabel('Emisiones Totales (toneladas)', fontsize=13)\n",
    "            plt.xticks(rotation=45, ha='right', fontsize=11)\n",
    "            plt.yticks(fontsize=11)\n",
    "            plt.legend(title='Año', title_fontsize='12', fontsize='11')\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Guardar gráfico\n",
    "            nombre_archivo = f'grafico_tendencia_{NOMBRE_MP25}_region_año_FUENTE_{fuente_actual}_{AÑOS_A_PROCESAR[0]}-{AÑOS_A_PROCESAR[-1]}.png'\n",
    "            ruta_guardado = os.path.join(CARPETA_GRAFICOS, nombre_archivo)\n",
    "            try:\n",
    "                plt.savefig(ruta_guardado, dpi=120)\n",
    "                print(f\"  -> Gráfico guardado en: '{ruta_guardado}'\")\n",
    "            except Exception as e_guardar:\n",
    "                print(f\"  Error al guardar gráfico para '{fuente_actual}': {e_guardar}\")\n",
    "            plt.close() # Cerrar figura\n",
    "\n",
    "        else:\n",
    "            print(f\"  INFO: No se encontraron datos de {NOMBRE_MP25} para la fuente '{fuente_actual}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
